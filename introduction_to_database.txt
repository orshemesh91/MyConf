Introduction
------------

Storage access times:
    L1 cache - 0.5 ns
	L2 cache - 7 ns
	DRAM -  100 ns
	SSD - 150,000 ns = 150 micro sec
	HDD - 10,000,000 ns = 10 milli sec
	Network storage - 30,000,000 ns = 30 milli sec
	tape archives - 1,000,000,000 ns = 1 sec

DBMS - database management system - allows definition, creation, querying, update and administration of databases
DML - data manipulation languages:
    Procedural (Relational Algebra) - the query specifies the high level strategy the DBMS should use to find the desired result.
        Relational algebra operators:
            Select
            Projection
            Union
            Intersection
            Difference
            Product
            Join
        Extra operators:
            Rename
            Assign
            Aggregate
            Sort
            Division
    Non-Procedural (Declarative) (Relational Calculus) - the query specifies only what data is wanted and not how to find it

SQL - Structured Query Language
-------------------------------
DML - Data Manipulation Language - actions on data
DDL - Data Definition Language - creating tables
DCL - Data Control Language - security and permissions
Aggregates - can only be used in the SELECT output list
    AVG(col)
    MIN(col)
    MAX(col)
    SUM(col)
    COUNT(col)
    example:
        SELECT COUNT(login) AS cnt FROM student WHERE login LIKE '@sc';
        SELECT COUNT(*) AS cnt FROM student WHERE login LIKE '@sc';
        SELECT COUNT(1) AS cnt FROM student WHERE login LIKE '@sc'; TODO Kopzon - why all 3 are the same?
    GROUP BY
        Non aggregated values in SELECT output, must appear in GROUP BY clause
        example:
            SELECT AVG(s.gpa), e.cid, s.name FROM enrolled AS e, student AS s WHERE e.sid = s.sid GROUP BY e.cid, s.name;
    HAVING
        Filters results based on aggregation computation (like WHERE clause for a GROUP BY)
        example:
            SELECT AVG(s.gpa) AS avg_gpa. e.cid FROM enrolled AS e, student AS s WHERE e.sid = s.sid GROUP BY e.cid HAVING avg_gpa > 3.9;
String operations:
    LIKE
        % - matches any substring (including empty ones)
        _ - matches aby one char
        example SELECT * FROM student AS s WHERE s.login LIKE 'kookoo%bomba_yal'
    SUBSTRING
        SELECT SUBSTRING(name,0,5) AS abbrv_name FROM student WHERE sid = 55843
    UPPER/LOWER
        SELECT * FROM student as s WHERE UPPER(e.name) LIKE 'KAN%'
    Concatinate
        ||
        +
        CONCAT(,)
Date and Time operatiopns:
    veries in diferent flavores of sequl
Output redirection:
    create new table
        SELECT DISTINCT cid INTO CourseIds FROM ENROLLED;
    add to existing table
        INSERT INTO CourseIds (SELECT DISTINCT cid FROM enrolled)
    ORDER BY <column> [ASC|DESC]
        SELECT sid FROM enrolled WHERE cid = '15-721' ORDER BY grade DESC, sid ASC (note that grade is not even part of the output)
    LIMIT <count> OFFSET [offset]
Window Functions:
    Like an aggregation but tuples are not grouped into a single output (you get the whole tuple in the output).
        SELECT ... FUNC-NAME(...) OVER(...) FROM tableName
        where FUNC-NAME can be:
            Aggregation functions...
            ROW_NUMBER() - # of the current row
            RANK() - order of the current row
Common table expressions
    useful to avoid query nasting.
        WITH cteName (col1, col2) AS (SELECT ...) SELECT * FROM cteName - col1 and col2 and bind to the temp table columns names
    can be used for recusrions:
        WITH RECURSIVE cteSource (counter) AS (
            (SELECT 1)
            UNION ALL
            (SELECT counter + 1 FROM cteSource WHERE counter < 10)
        )
        SELECT * FROM cteSource;

Memory Management
-----------------
Why not using mmap()
    The OS doesn't know what really does the application do, so swap stalls are very heavy. A good workaround for this issue is:
        madvice() - tell the OS how you expect to read the pages
        mlock() - mark memory ranges that cannot be paged out
        msync() - flush memory
    still this isn't a good solution for multiple writers. (Full usage - monetDC, LMDB, ravenDB, levelDB elasticsearch)
    OS is general purpose track, while our system is a Porche or Ferrari
    TODO Kopzon - managing our own file system in a big pain in the ass and can give not more than 10% performance enhancement. (is it true?)

How the DBMS represents the DB in files on disk?
    Page contains unique sort of data (tuples, meta-data, indexes, log records...)    
    indirection layer to map page id to file and offset.
    DB page size is 512B-16KB (ORACLE, IBM DB2 and SQLite - 4KB) (MySQL - 16KB high end) high end systems usually give choice with DB page size per type
    Hardware pages are 4KB atomic
    page directory - lookup table for pages on disk
    page contents:
        Header:
            page size
            checksum
            BDMS version
            Transaction visibility TODO Kopzon - what is it?
            Compression info
        1st option:
            Slot array - mapping layer from a slot to a tuple (slot array growing from beginning to the end and tuples grow from end to beginning)
            Tuples
        2nd option:
            Log structured - Append records to a log file when DB is modified. (good for writes, bad for reads, but you can periodically build indexes and compact logs)
                Insert - store the entire tuple
                Delete - mark the tupl as deleted
                Update contain the delta of the modified attribute
    GC compacts the tuples in a page
    tuple contents:
        header
        attributes
        BLOB - Binary Large OBject - is a tuple which's content is too big. Can be handles by:
            few pages with indirection (like a list of pages)
            within an external file (DBMS can't manipulate these files)
    normalization - the way you split up the DB across different tables
    denormalization - pre joining - create a join table instead of two tables (cloud spanner from Google - protobuf nested tables use denormalization)
    Table schema - meta data of a table in the DB (can sit inside the DB itself or rely on external FS)
    Transaction types:
        OLTP - Online transaction processing - simple mostly write queries, small amount of data involved
        OLAP - Online analytical processing - complex mostly read queries, large amount of data
        HTAP - Hybrid transactional analytical processing
    mongoDB, bigTable and kasandra are OLTP optimized and are noSQL systems and this is why the are able to scale TODO Kopzon - why and what does it mean?
    storage models:
        n-ary (row store) - all the attributes of a single tuple are stored continuesly in a single page - best for OLTP workloads
        DSM (column store) - Decomposition Storage Model - best for OLAP workloads (analytics). How do we match different attributes of same tuple?
            fixed length offsets - issue with variable length attributes
            embedded tuple ids - waste of space
        get 4KB page from SSD - 150micro, scan 4KB in INT32 jumps is 33micro (3Ghz processor, 10clock cycles per loop)? TODO Kopzon - check
        It is a common solution to store the DB with a row transactional store (OLTP) for real time transaction based applications and when the data starts to be less relevant (in time for example) it is copied to a backend column analytical store (OLAP).

How the DBMS manages it's memory and moves data back and forth from disk?
    allocate a memory region called buffer cache (frame pool) and bring needed pages from dist to it.
    Use page table to map page to frame in the pool.
    save dirty and reference bits on frames to control correct swapping.
    lock - high level transaction syncronization mechanism (should be able to roll back transactions etc...)
    latch - low level lock for protecting data resources from multi-threaded corruption.
    page directory - where is the page in the disk (must be durable)
    page table - where is the page in the buffer pool (don't have to be durable)
    pre-fetching - OS prefetchs pages using simple locality heuristic. The DBMS can pre-fetch non-sequential pages based on table indexes and query requirements.
    scan sharing - allow multiple queries attach to a single table cursor that scans the table. (queries don'thave to be exactly the same)
    result caching - save query result in cache to output it on demand for the same query in the future
    buffer cache bypass - for sort/ large sequential queries - allocate temporary memory for pages for the specific query to reduce buffer cache cooling (with regard to other queries that use the buffer cache and made it "hot" for them)
    most DBMS use O_DIRECT (direct IO) to avoid using the OS page cache.
    page replacement policy
        LRU
            time stamp per page in page table + scan all pages in page table vor every page removal operation (wase of time to iterrate)
            queue - add to the end, remove from the beginning + reinsert all pages that are reused (the queue lock is contended)
            clock - approximation of LRU - hold all pages in a cyrcular buffer. if page is referenced, update bRef to 1. when page should be swapped out the if the clock arrow points to a page with bRef = 1, assign bRef = 0 and go to the next one, otherwise swap this page. (no need for taking lock on cache hit, just update bRef)
            note:
                sequential flooding - cache trashing on one sequential query
        LRU-K
            track the lask K references to each page and remove from cache the one with the biggest AVG interval between timestamps
        Localization per query - hold page cache per query and not a global one
        Priority Hints - knowing the query structure we can save in cache the most frequently needed pages for the query

Hash Tables:
    Linear Search - on collision put the new key at the first available slot after it's optimal slot.
        Robin Hood hashing - each inserted key stores it's distance from it's optimal slot, and if new key's distance is greater then the old in the slot, they are swapped.
        CuKoo Hashing - multiple hash functions and hash tables. insert to the hash that doesn't have a collision. If there is a collision, replace the old key and reinsert it to another hash. Do it in a loop till you reinsert all key's or recognize you need to extent the hash table size.
        In case of resize we have to rebuild the entire table
    Chain hashing - each entry maps to a bucket of keys.
    Extendible hashing - Like chain hashing, but the pointers table  has a global counter that represents the amount of  bits to we have to look at when searcing for bucket (page) with data. When a bucket is getting full, we split only this bucket, double the pointer's table size, increasing the global bit counter and update the pointers (updating only 3 pages for resize)
    Linear haashing - splitting buckets based on the split pointer, double the slot array, add new hash function with modulo X2 from the previous hash function and remove the old hash function when the split pointer gets to the end of the slot array. To find a key use the first hash function and if the result is above the split pointer we may need to use the second hash function. split pointer can move back and slot arary can shrink by two when a splitted bucket gets empty

B-Trees:
    The main difference between B-Tree and a B+Tree is in B-Tree there are no duplicates of keys (data is all over the tree and not only in leaves) so it is more compact, but it is not used since it is much more efficient to multi-thread over B+Tree (data in only in leaves so taking latch will not block other leaves from being updated)
    why B+trees are better than hash tables for indexing?
        tuples are sorted in the key order on disk - range queries are faster and require less page accesses.
        can do a partial key search (wild card searches e.g <A,*>)
    variable key sizes - use in-page indirection table that grows from the beginning of the node (page) while the key values + data themselves grow from the end (like  a slot array) nice trick - save the first character of the real key in the slot array entries to avoid ram cache garbeging and redundent lookups.
    node optimizations:
        prefix compression - most of the keys in a leaf are very similar (at least same prefix), so there is no point in storing the common prefix multiple times
        suffix truncation - in the inner nodes of the B+Tree we can store only some prefix which is just enough to navigate threw the tree
        bulk insert - if you have all the keys ahead of time you can sort them and build a B+Tree from buttom to up(top) it is much faster (O(n) and not O(n*log(n))
        pointer swizzling - if a page is pinned, store the direct pointer to a frame in the buffer cache instead of the page id to reduce page table access
    non-unique keys:
        can be handled "as usual" - reorder the relevant page and split if needed
        use an "overflow page". This overflow page can be sorted (slower to insert and maintain) or unordered.
    Partial indexes - can save partial key set - optimizes specific queries
    Covering index - can save partial tuple data inside the index itself - to avoid indirection to the tuple itself
    Index include columns - add some attributes to a Covering index
    Functional/Expression index - like a partial index build on some function or expression over the attributes (not the attribute itself)

Trie:
    used to determine whether a key exists or not to avoid searching by the index and potentially get multiple page misses
    Trie is faster for point queries, B+ faster for scans
    horizontal compression - remove the values from the inner nodes, store only the pointers (the values order in each node's array is a predefined known convention you define)
    vertical compression - if there is only one key for some prefix, don't save the whole path till the end of the key string, point to the corresponding tuple immediately.
    Radix tree - Trie with vertical and horizontal compression.

Inverted index (full-text search index):
    stores a mapping of words to records that contain those words in the target attribute.

Multi-threading:
    OS mutex - is ~30ns for each acquire and release. It tries to test and set at the user space (futex) and if fails goes to the kernel mutex which reschedules the whole thread.
    std::atomic_flag latch - can use "while (latch.test_and_set()) { /*retry? yield? abort?*/ }" to have more control over the multi threading in the system
    Hash table - lock the entry you need, in linear search collision case lock the next node and release the previous. may first lock for read only the check whether the node contains the key we need and only if yes to take a write lock.
    B+Tree - latch crabbing/coupling - get parent latch, get child latch, release parent latch if safe (node not full on "add" node not half full at "delete") - use a stack of latches (queue is better from performance stand point). Same as in Hash tables, first use a read latch and only if we got to the leaf node (which takes a write latch) and it has to do a rebalance operation, only then re-take the needed write latches on the relevant parents.
    Lazy parent updates in B+Trees - have a global table with inner nodes that have to be updated due to previous splits. the split command only creates the new node and links it to the sibling leaf. only the next command that will get the parent's lock will update it. TODO Kopzon - so now we have to create another if statement on every inner node?!?
	Sibling pointer latches should kill the operation if stuck due to colission with vertical latches to avoid deadlocks.
	
JOIN Algorithms:
    Operator output:
	    data - save a brand new tuple with the needed attributes from the joined tables (can be optimized to filter out the redundant attributes if they are known from the query itself)
        record id (late materialization) - save a tuple with page id and record id (pointers) (not good for high scale systems)
    Nested Loop algorithm - if memory has B free blocks then bring B-2 blocks from the outer relation to memory and scan threw the inner relation blocks one by one (ont block for input and one for output). This one is mostly used when one of the relations fits the RAM
    Sort-Merge Algorithm - first sort the relations and then merge them (may need backtrack on the inner relation (save pointer of the first time you saw a value when incrementing the inner relation pointer))
	    If the relation has an index that already sorted we don't have to do the sort phase.
	    If we have an ORDER BY clause on the same attribute, then the JOIN's sorting operation output can be used for the ORDER BY calculation
	Hash Algorithm - put both relations to a hash table by same hash function (first the outer relation then the inner). then go over the buckets and output the join.
        optimization - build a bloom filter when creating the outer hash table.
            bloom filter - "one way" filter - lookup bit map which supports insert() and lookup() API.
        recursive partitioning - if a partition (buket of outer and inner relations) doesn't fit memory, the do another loop of hash with another hash function

Query Plan:
	Processing model:
        Iterator model (pipeline) - for each query operator we implement a next() function. Each tuple is propagated threw all query functions in a pipeline. Good for OLAP data model - complex read queries can be processed in pipeline giving a high threughput with relatively low memory consumption.
        Materialization model - each operator processes all tuples at once and outputs all at once. Can use hints from the DBMS to optimize per query. Good for OLTP data model - small amount of tuples involved so using smaller amount of functions invocations and branches. Good for in-memory systems.
        Vectorization model - like Iterator model but instead of each tuple propagate a block of tuples at once (batch processing). Best for OLAP
    Sequential scan optimizations:
        Prefetching
		Buffer pool bypass
		Paralleization
		Zone maps - for each page save a meta data (in the page itself or in another dedicated page) that gives hints which help queries not access pages they don't need. Good for OLAP since they mostly don't update the tuples and so don't have to update the zone maps syncroniousely all the time
		Late materialization - delay stiching togather tuples untill the upper part of the query plan - passing only offsets (pointers) if the upper parts don't really need the aggregation attribute from the lower parts.
		Heap clustering - use sorted indexes where able to
	Index scan:
        scan threw an index (can by multiple indexes and then an intersention or union between them). The DBMS Optimizer decides whether to use index or sequential scan.
        if the index is unclustered, first figure out all the tuples needed for the query, sort them by their page id and then bring them to memory by their page id order to avoid buffer cache garbeging
    Expression trees are the high level query plan. They are flexible but slow. High end systems know to take a query template, parameters for it and compile down at run time the query plan code to a dedicated function instead of having a bunch of generic functions with multiple switch case statements that match all tupes of queries.

TCO - Total Cost of Ownership - hardwre + sofrware + run time + maintenence + .....

Parallel vs distributed:
    Parallel is multithreading/multiresources on a single machine
    Distributed is across multiple servers
Processing parallelizm:
    inter query
    intra query
        inter operator
		intra operator
    exchange operator - inner DBMS operation which is responsible of gathering data together after multi-threaded execution.
storage parallelizm:
    basically the DBMS doesn't care about it and sits on anpther layer that controls the storage (e.g raid controller). The DBMS just controls the logical partitioning
        horizontal partitioning - sharding - different tupples of same table on different storage devices
	    vertical partitioning - different attributes on different storage devices

Query optimization:
    